"""
Word1 í´ë”ì˜ DOCX íŒŒì¼ì—ì„œ ì¹˜í—˜ë¡€ ë°ì´í„° ì¶”ì¶œí•˜ì—¬ Supabaseì— ì‚½ì…
"""

from docx import Document
from pathlib import Path
import requests
import re
import json

# Supabase ì„¤ì •
SUPABASE_URL = "https://bbwnroljrrbwnewmamno.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImJid25yb2xqcnJid25ld21hbW5vIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc2Nzk0NDAzMCwiZXhwIjoyMDgzNTIwMDMwfQ.TIzhIHYDLzYC_BPEIzMWgvCIQvOcPZUHhMxsQVJ7svg"

HEADERS = {
    "apikey": SUPABASE_KEY,
    "Authorization": f"Bearer {SUPABASE_KEY}",
    "Content-Type": "application/json",
    "Prefer": "return=minimal"
}

# Word1 í´ë” DOCX íŒŒì¼ ëª©ë¡ê³¼ ìœ í˜•
DOCX_FILES = {
    "ì‚¬ìƒ ì†Œì–‘ì¸ ì¹˜í—˜ë¡€ ëª¨ìŒ(081024).docx": {"type": "sasang", "constitution": "ì†Œì–‘ì¸"},
    "ì‚¬ìƒ ì†ŒìŒì¸ ì¹˜í—˜ë¡€ ëª¨ìŒ(081024).docx": {"type": "sasang", "constitution": "ì†ŒìŒì¸"},
    "ì‚¬ìƒ íƒœì–‘ì¸ ì¹˜í—˜ë¡€ ëª¨ìŒ081025.docx": {"type": "sasang", "constitution": "íƒœì–‘ì¸"},
    "ì‚¬ìƒ íƒœìŒì¸ ì¹˜í—˜ë¡€ ëª¨ìŒ(081024).docx": {"type": "sasang", "constitution": "íƒœìŒì¸"},
    "ìµœê²½êµ¬. ì‚¼ë¡€. ì—°ìˆ˜ë‹¹. í‘ìƒ‰ì¢…..docx": {"type": "individual", "description": "í‘ìƒ‰ì¢… ì¹˜í—˜ë¡€"},
    "1ì°¨ë³¸1.ê³ ë ¹ìì±„ë¡ëª¨ìŒì§‘.22.5.12.ì´ì¢…ëŒ€.docx": {"type": "goreyongja", "description": "ê³ ë ¹ìì±„ë¡ëª¨ìŒì§‘"},
}


def extract_gender(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ì„±ë³„ ì¶”ì¶œ"""
    search_text = text[:500]

    if re.search(r'ë‚¨\s*\d{1,3}\s*ì„¸', search_text) or re.search(r'\d{1,3}\s*ì„¸\s*ë‚¨', search_text):
        return 'male'
    if re.search(r'ì—¬\s*\d{1,3}\s*ì„¸', search_text) or re.search(r'\d{1,3}\s*ì„¸\s*ì—¬', search_text):
        return 'female'

    if re.search(r'[â—‹0\s]{3,}\s+ë‚¨\s+\d', search_text):
        return 'male'
    if re.search(r'[â—‹0\s]{3,}\s+ì—¬\s+\d', search_text):
        return 'female'

    first_200 = text[:200]
    if 'ë‚¨ì„±' in first_200 or re.search(r'\së‚¨\s', first_200):
        return 'male'
    if 'ì—¬ì„±' in first_200 or re.search(r'\sì—¬\s', first_200):
        return 'female'

    return 'unknown'


def extract_age_range(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ì—°ë ¹ëŒ€ ì¶”ì¶œ"""
    search_text = text[:500]

    match = re.search(r'(\d{1,3})\s*ì„¸', search_text)
    if match:
        age = int(match.group(1))
        if age < 10: return "0-9ì„¸"
        elif age < 20: return "10ëŒ€"
        elif age < 30: return "20ëŒ€"
        elif age < 40: return "30ëŒ€"
        elif age < 50: return "40ëŒ€"
        elif age < 60: return "50ëŒ€"
        elif age < 70: return "60ëŒ€"
        elif age < 80: return "70ëŒ€"
        else: return "80ì„¸ ì´ìƒ"
    return None


def extract_constitution(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ì²´ì§ˆ ì¶”ì¶œ"""
    search_text = text[:1000]
    constitutions = ['íƒœì–‘ì¸', 'íƒœìŒì¸', 'ì†Œì–‘ì¸', 'ì†ŒìŒì¸']
    for const in constitutions:
        if const in search_text:
            return const
    return None


def extract_formula_name(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ì²˜ë°©ëª… ì¶”ì¶œ"""
    search_text = text[:800]

    match = re.search(r'([ê°€-í£]{2,10}(?:íƒ•|ì‚°|í™˜|ì›|ê³ |ë‹¨|ìŒ|ì „|ì|í¬))', search_text)
    if match:
        return match.group(1)
    return None


def extract_chief_complaint(text, title=""):
    """ì£¼ì¦ìƒ ì¶”ì¶œ"""
    if '--' in title:
        parts = title.split('--')
        if len(parts) > 1:
            complaint = parts[-1].strip()
            if complaint and len(complaint) > 2:
                return complaint[:500]

    patterns = [
        r'[ï¿­â—â– â—†â–¶]\s*ì£¼\s*ì¦\s*ìƒ\s*[:\s]*\n?([\s\S]*?)(?=[ï¿­â—â– â—†â–¶]|\n\n)',
        r'ì£¼ì¦ìƒ[:\s]*\n?([\s\S]*?)(?=ë¶€ìˆ˜ì¦ìƒ|ì°¸ê³ |ë³€ìƒ|ë³€ì¦|\n\n)',
        r'â‘ \s*(.+?)(?:â‘¡|$)',
    ]

    for pattern in patterns:
        match = re.search(pattern, text[:3000])
        if match:
            complaint = match.group(1).strip()
            complaint = re.sub(r'\s+', ' ', complaint)
            if complaint and len(complaint) > 5:
                return complaint[:500]

    formula = extract_formula_name(text)
    if formula:
        return f"{formula} ì¹˜í—˜ë¡€"

    return title[:500] if title else "ì¹˜í—˜ë¡€"


def extract_symptoms(text):
    """ì¦ìƒ ëª©ë¡ ì¶”ì¶œ"""
    symptoms = []

    circle_matches = re.findall(r'[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]\s*(.+?)(?=[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]|\n\n|$)', text[:3000])
    for match in circle_matches[:10]:
        symptom = re.sub(r'\s+', ' ', match.strip())
        if 2 < len(symptom) < 200:
            symptoms.append({"name": symptom, "severity": None, "duration": None, "bodyPart": None})

    if not symptoms:
        num_matches = re.findall(r'\d+\.\s*(.+?)(?=\d+\.|$)', text[:2000])
        for match in num_matches[:10]:
            symptom = re.sub(r'\s+', ' ', match.strip())
            if 2 < len(symptom) < 200:
                symptoms.append({"name": symptom, "severity": None, "duration": None, "bodyPart": None})

    return symptoms if symptoms else None


def split_sasang_cases(doc_text, file_info):
    """ì‚¬ìƒì²´ì§ˆ ì¹˜í—˜ë¡€ ë¶„í•  - íŒ¨í„´: â–  ì²˜ë°©ëª…(ë²ˆí˜¸) -- ì¦ìƒ"""
    cases = []

    pattern = r'â– \s*([ê°€-í£]+(?:íƒ•|ì‚°|í™˜|ì›|ê³ |ë‹¨|ìŒ|ì „|ì|í¬))\s*\((\d+-\d+-\d+|\d+-\d+)\)\s*(?:--|â€”|â€“)?\s*'

    splits = re.split(pattern, doc_text)

    if len(splits) > 3:
        for i in range(1, len(splits) - 2, 3):
            formula_name = splits[i].strip()
            case_number = splits[i + 1].strip()
            content = splits[i + 2].strip()

            if len(content) > 100:
                first_line = content.split('\n')[0].strip()
                title = f"{formula_name}({case_number}) -- {first_line}"

                cases.append({
                    'title': title[:300],
                    'content': content[:15000],
                    'formula_name': formula_name,
                    'case_number': case_number,
                    'constitution': file_info.get('constitution')
                })

    return cases


def split_goreyongja_cases(doc_text, file_info):
    """ê³ ë ¹ìì±„ë¡ ì¹˜í—˜ë¡€ ë¶„í• """
    cases = []

    pattern = r'\n\s*(?:\d+\.\s*)?([ê°€-í£]+(?:íƒ•|ì‚°|í™˜|ì›|ê³ |ë‹¨|ìŒ|ì „|ì|í¬))\s+(\d+-\d+)\.\s*'

    splits = re.split(pattern, doc_text)

    if len(splits) > 3:
        for i in range(1, len(splits) - 2, 3):
            formula_name = splits[i].strip()
            case_number = splits[i + 1].strip()
            content = splits[i + 2].strip()

            if len(content) > 50:
                first_line = content.split('\n')[0].strip()[:100]
                title = f"{formula_name} {case_number}. {first_line}"

                cases.append({
                    'title': title[:300],
                    'content': content[:15000],
                    'formula_name': formula_name,
                    'case_number': case_number,
                    'constitution': None
                })

    return cases


def split_individual_case(doc_text, file_info, filename):
    """ê°œë³„ ì¹˜í—˜ë¡€ íŒŒì¼"""
    cases = []

    if len(doc_text) > 100:
        formula_name = extract_formula_name(doc_text)
        description = file_info.get('description', filename)

        cases.append({
            'title': f"{formula_name}: {description}" if formula_name else description,
            'content': doc_text[:15000],
            'formula_name': formula_name,
            'case_number': "1",
            'constitution': None
        })

    return cases


def split_into_cases(doc_text, filename, file_info):
    """íŒŒì¼ ìœ í˜•ì— ë”°ë¼ ì¹˜í—˜ë¡€ ë¶„í• """
    file_type = file_info.get('type', 'individual')

    if file_type == "sasang":
        cases = split_sasang_cases(doc_text, file_info)
    elif file_type == "goreyongja":
        cases = split_goreyongja_cases(doc_text, file_info)
    else:
        cases = split_individual_case(doc_text, file_info, filename)

    # Fallback
    if not cases and len(doc_text) > 500:
        print(f"  âš  ë¶„í•  ì‹¤íŒ¨, Fallback ì ìš©")

        chunk_size = 8000
        chunks = []
        pos = 0

        while pos < len(doc_text):
            end_pos = min(pos + chunk_size, len(doc_text))
            para_end = doc_text.rfind('\n\n', pos, end_pos)
            if para_end > pos + 1000:
                end_pos = para_end

            chunk = doc_text[pos:end_pos].strip()
            if len(chunk) > 500:
                chunks.append(chunk)
            pos = end_pos

        for idx, chunk in enumerate(chunks[:50]):
            formula = extract_formula_name(chunk)
            cases.append({
                'title': f"{filename} - ì¹˜í—˜ë¡€ {idx + 1}",
                'content': chunk,
                'formula_name': formula,
                'case_number': str(idx + 1),
                'constitution': file_info.get('constitution')
            })

    return cases


def parse_docx_file(file_path, file_info):
    """DOCX íŒŒì¼ íŒŒì‹±"""
    try:
        doc = Document(str(file_path))
        filename = file_path.name

        full_text = '\n'.join([p.text for p in doc.paragraphs])

        print(f"  ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {len(full_text)}ì")

        raw_cases = split_into_cases(full_text, filename, file_info)
        print(f"  ë¶„í• ëœ ì¹˜í—˜ë¡€: {len(raw_cases)}ê±´")

        db_cases = []
        for idx, raw_case in enumerate(raw_cases):
            content = raw_case['content']
            title = raw_case['title']
            formula_name = raw_case.get('formula_name')
            case_number = raw_case.get('case_number', str(idx + 1))
            constitution = raw_case.get('constitution')

            if not constitution:
                constitution = extract_constitution(content)

            source_id = f"docx-word1-{filename}-{case_number}".replace(" ", "_")

            db_case = {
                "sourceId": source_id[:100],
                "recordedYear": 2008,
                "recorderName": "ì´ì¢…ëŒ€",
                "patientGender": extract_gender(content),
                "patientAgeRange": extract_age_range(content),
                "patientConstitution": constitution,
                "chiefComplaint": extract_chief_complaint(content, title),
                "presentIllness": None,
                "patternDiagnosis": None,
                "clinicalNotes": None,
                "originalText": content[:10000],
                "symptoms": extract_symptoms(content),
                "herbalFormulas": [{"formulaName": formula_name, "herbs": [], "dosage": None}] if formula_name else None,
            }
            db_cases.append(db_case)

        return db_cases

    except Exception as e:
        print(f"  âš  íŒŒì‹± ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return []


def delete_existing_docx_cases():
    """ê¸°ì¡´ DOCX word1 ê¸°ë°˜ ì¹˜í—˜ë¡€ ì‚­ì œ"""
    print("\nê¸°ì¡´ DOCX word1 ê¸°ë°˜ ì¹˜í—˜ë¡€ ì‚­ì œ ì¤‘...")

    try:
        response = requests.delete(
            f"{SUPABASE_URL}/rest/v1/clinical_cases",
            headers=HEADERS,
            params={"sourceId": "like.docx-word1-%"}
        )

        if response.status_code in [200, 204]:
            print("  âœ“ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
        else:
            print(f"  ì‚­ì œ ì‘ë‹µ: {response.status_code}")

    except Exception as e:
        print(f"  ì‚­ì œ ì˜¤ë¥˜: {e}")


def insert_cases(cases, batch_size=50):
    """Supabaseì— ì‚½ì…"""
    total = len(cases)
    inserted = 0
    failed = 0

    upsert_headers = {
        **HEADERS,
        "Prefer": "resolution=merge-duplicates"
    }

    for i in range(0, total, batch_size):
        batch = cases[i:i+batch_size]

        try:
            response = requests.post(
                f"{SUPABASE_URL}/rest/v1/clinical_cases",
                headers=upsert_headers,
                json=batch
            )

            if response.status_code in [200, 201]:
                inserted += len(batch)
            else:
                failed += len(batch)
                if failed <= 10:
                    print(f"  ì‚½ì… ì‹¤íŒ¨: {response.status_code} - {response.text[:200]}")

        except Exception as e:
            failed += len(batch)
            print(f"  ì‚½ì… ì˜¤ë¥˜: {e}")

    return inserted, failed


def main():
    print("=" * 70)
    print("  DOCX ì¹˜í—˜ë¡€ íŒŒì¼ (word1) â†’ Supabase DB ì‚½ì…")
    print("=" * 70)

    # Google Drive ê²½ë¡œ ì§ì ‘ ì§€ì •
    docx_dir = Path(r"G:\ë‚´ ë“œë¼ì´ë¸Œ\developer\hanmed-cdss\ì¹˜í—˜ë¡€\word1")

    if not docx_dir.exists():
        print(f"\nâš  ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {docx_dir}")
        return

    # ì‹¤ì œ íŒŒì¼ ëª©ë¡ í™•ì¸
    print(f"\në””ë ‰í† ë¦¬: {docx_dir}")
    print("DOCX íŒŒì¼ ê²€ìƒ‰ ì¤‘...")

    # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
    delete_existing_docx_cases()

    all_cases = []
    stats = {"sasang": 0, "goreyongja": 0, "individual": 0}
    processed_files = []

    print("\n" + "=" * 70)
    print("  íŒŒì¼ ì²˜ë¦¬ ì‹œì‘")
    print("=" * 70)

    for filename, file_info in DOCX_FILES.items():
        file_path = docx_dir / filename

        if file_path.exists():
            print(f"\n[{file_info['type']}] {filename}")

            cases = parse_docx_file(file_path, file_info)

            if cases:
                sample = cases[0]
                print(f"  ìƒ˜í”Œ - ì£¼ì¦ìƒ: {sample['chiefComplaint'][:50]}...")
                print(f"  ìƒ˜í”Œ - ì„±ë³„: {sample['patientGender']}, ë‚˜ì´: {sample['patientAgeRange']}, ì²´ì§ˆ: {sample['patientConstitution']}")

                all_cases.extend(cases)
                stats[file_info['type']] += len(cases)
                processed_files.append({
                    'filename': filename,
                    'type': file_info['type'],
                    'cases_count': len(cases),
                    'constitution': file_info.get('constitution'),
                    'table': 'clinical_cases',
                    'source_prefix': f"docx-word1-{filename}"
                })
        else:
            print(f"\nâš  íŒŒì¼ ì—†ìŒ: {filename}")

    # í†µê³„ ì¶œë ¥
    print("\n" + "=" * 70)
    print("  ì¶”ì¶œ í†µê³„")
    print("=" * 70)
    for file_type, count in stats.items():
        print(f"  {file_type:12}: {count:5}ê±´")
    print(f"  {'ì´ê³„':12}: {len(all_cases):5}ê±´")

    # DB ì‚½ì…
    if all_cases:
        print("\n" + "=" * 70)
        print("  Supabase DB ì‚½ì… ì¤‘...")
        print("=" * 70)

        inserted, failed = insert_cases(all_cases)

        print(f"\n  âœ“ ì™„ë£Œ!")
        print(f"    - ì‚½ì… ì„±ê³µ: {inserted}ê±´")
        print(f"    - ì‚½ì… ì‹¤íŒ¨: {failed}ê±´")
    else:
        print("\nâš  ì‚½ì…í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ìƒì„¸ ë³´ê³ 
    print("\n" + "=" * 70)
    print("  ğŸ“Š íŒŒì¼ë³„ ì ì¬ ë³´ê³ ì„œ")
    print("=" * 70)

    for pf in processed_files:
        print(f"""
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ ğŸ“„ íŒŒì¼: {pf['filename'][:50]}
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ â€¢ íŒŒì¼ ìœ í˜•      : {pf['type']}
  â”‚ â€¢ ì‚¬ìƒì²´ì§ˆ       : {pf.get('constitution') or 'ë³¸ë¬¸ì—ì„œ ì¶”ì¶œ'}
  â”‚ â€¢ ì¶”ì¶œ ê±´ìˆ˜      : {pf['cases_count']}ê±´
  â”‚ â€¢ ì €ì¥ í…Œì´ë¸”    : {pf['table']}
  â”‚ â€¢ sourceId í˜•ì‹  : {pf['source_prefix'][:40]}...
  â”‚ â€¢ ê²€ìƒ‰ ë°©ë²•      : sourceId LIKE 'docx-word1-{pf['filename'][:20]}%'
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜""")

    # DB ë§¤í•‘ ê·¼ê±°
    print("\n" + "=" * 70)
    print("  ğŸ“‹ DB ë§¤í•‘ ê·¼ê±°")
    print("=" * 70)
    print("""
  clinical_cases í…Œì´ë¸” ì»¬ëŸ¼ ë§¤í•‘:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ ì»¬ëŸ¼                â”‚ ì¶”ì¶œ ê·¼ê±°                                  â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ sourceId            â”‚ "docx-word1-{íŒŒì¼ëª…}-{ì¼€ì´ìŠ¤ë²ˆí˜¸}"         â”‚
  â”‚ recordedYear        â”‚ 2008 (íŒŒì¼ ì‘ì„± ì‹œê¸°)                      â”‚
  â”‚ recorderName        â”‚ "ì´ì¢…ëŒ€" (ì €ì)                            â”‚
  â”‚ patientGender       â”‚ "ë‚¨/ì—¬ NNì„¸" íŒ¨í„´ ì¶”ì¶œ                    â”‚
  â”‚ patientAgeRange     â”‚ "NNì„¸" â†’ ì—°ë ¹ëŒ€ ë³€í™˜                      â”‚
  â”‚ patientConstitution â”‚ íŒŒì¼ëª…(ì‚¬ìƒ) ë˜ëŠ” ë³¸ë¬¸ì—ì„œ ì¶”ì¶œ           â”‚
  â”‚ chiefComplaint      â”‚ "â–  ì²˜ë°©ëª… -- ì¦ìƒ" ë˜ëŠ” ì£¼ì¦ìƒ ì„¹ì…˜      â”‚
  â”‚ originalText        â”‚ ë¶„í• ëœ ì¹˜í—˜ë¡€ ë³¸ë¬¸ (ìµœëŒ€ 10,000ì)       â”‚
  â”‚ symptoms            â”‚ â‘ â‘¡â‘¢ ë˜ëŠ” 1.2.3. íŒ¨í„´                     â”‚
  â”‚ herbalFormulas      â”‚ "OOíƒ•/ì‚°/í™˜" íŒ¨í„´ â†’ formulaName          â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)

    # ê²€ìƒ‰ ì˜ˆì‹œ
    print("\n" + "=" * 70)
    print("  ğŸ” ê²€ìƒ‰ ì˜ˆì‹œ (Supabase)")
    print("=" * 70)
    print("""
  -- ì†Œì–‘ì¸ ì¹˜í—˜ë¡€ ê²€ìƒ‰
  SELECT * FROM clinical_cases
  WHERE "patientConstitution" = 'ì†Œì–‘ì¸';

  -- íŠ¹ì • íŒŒì¼ì—ì„œ ì¶”ì¶œëœ ì¹˜í—˜ë¡€ ê²€ìƒ‰
  SELECT * FROM clinical_cases
  WHERE "sourceId" LIKE 'docx-word1-ì‚¬ìƒ ì†Œì–‘ì¸%';

  -- ì²˜ë°©ëª…ìœ¼ë¡œ ê²€ìƒ‰
  SELECT * FROM clinical_cases
  WHERE "herbalFormulas"::text LIKE '%í˜•ë°©ì§€í™©íƒ•%';

  -- ì£¼ì¦ìƒ í‚¤ì›Œë“œ ê²€ìƒ‰
  SELECT * FROM clinical_cases
  WHERE "chiefComplaint" ILIKE '%ë‘í†µ%';
    """)


if __name__ == "__main__":
    main()
